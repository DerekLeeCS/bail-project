{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jail_web_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Dict\n",
        "from enum import Enum, unique\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "import urllib\n",
        "import requests\n",
        "import ssl\n",
        "import certifi\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import threading\n",
        "import IPython\n",
        "\n",
        "# Used for debugging; pretty print JSON strings\n",
        "import json"
      ],
      "metadata": {
        "id": "OS7Po5Gqy7tr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhqLGdsry29O"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/'):\n",
        "    raise Exception(\"Error: Mount Google Drive before continuing!\")\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/Data Science for Social Good - Spring 2022/data/'\n",
        "\n",
        "# Define directory that contains intermediate SSL certificates\n",
        "CERT_DIR = BASE_DIR + 'certificates/'\n",
        "\n",
        "# Define directories to save data\n",
        "SCRAPE_DIR = BASE_DIR + 'scraped_files/'\n",
        "DATA_DIR = SCRAPE_DIR + 'DATA/'\n",
        "\n",
        "current_date = datetime.now(timezone('US/Eastern')).strftime(\"%m-%d-%Y\")\n",
        "\n",
        "# Create all directories on the given paths if needed\n",
        "os.makedirs(DATA_DIR + current_date, exist_ok=True)\n",
        "print(\"Date used for scraping:\", current_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9MsX6May6ms",
        "outputId": "dbb34584-a7f2-4713-cae4-dba2dbb54835"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date used for scraping: 03-17-2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions and Classes"
      ],
      "metadata": {
        "id": "fR8wSuIfzlDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@unique\n",
        "class CountyWithCaptcha(Enum):\n",
        "    DESOTO = 'DeSoto'\n",
        "    FORREST = 'Forrest'\n",
        "    HANCOCK = 'Hancock'\n",
        "    HARRISON = 'Harrison'\n",
        "    LAMAR = 'Lamar'\n",
        "    MARION = 'Marion'\n",
        "    PERRY = 'Perry'\n",
        "    YAZOO = 'Yazoo'\n",
        "\n",
        "    # Return Name, rather than CountyWithCaptcha.Name\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "@unique\n",
        "class CountyWithoutCaptcha(Enum):\n",
        "    # The commented out counties only have the total bond, not bond by crime\n",
        "    # PEARL_RIVER = 'PearlRiver'\n",
        "    JACKSON = 'Jackson'\n",
        "    # MADISON = 'Madison'\n",
        "    # # ADAMS = 'Adams'\n",
        "    # # CLAY = 'Clay'\n",
        "    # # JONES = 'Jones'\n",
        "    # # TUNICA = 'Tunica'\n",
        "\n",
        "    # Return Name, rather than CountyWithoutCaptcha.Name\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "# Define a custom type to pass into functions\n",
        "County = Union[CountyWithCaptcha, CountyWithoutCaptcha]\n",
        "\n",
        "\n",
        "def get_county_filename(county: County) -> str:\n",
        "    return f'{str(current_date)}_{county.value}.csv'"
      ],
      "metadata": {
        "id": "6a2YyDv2zpw4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jail_captcha_links = {\n",
        "    CountyWithCaptcha.DESOTO: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/DeSoto_County_MS/',\n",
        "    CountyWithCaptcha.FORREST: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Forrest_County_MS/',\n",
        "    CountyWithCaptcha.HANCOCK: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/HANCOCK_COUNTY_MS/',\n",
        "    CountyWithCaptcha.HARRISON: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/HARRISON_COUNTY_JAIL_MS/',\n",
        "    CountyWithCaptcha.LAMAR: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Lamar_County_MS/',\n",
        "    CountyWithCaptcha.MARION: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Marion_County_MS/',\n",
        "    CountyWithCaptcha.PERRY: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Perry_County_MS/',\n",
        "    CountyWithCaptcha.YAZOO: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Yazoo_County_MS/',\n",
        "}"
      ],
      "metadata": {
        "id": "1FnFWhPZ4NQx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_url(request: Union[str, urllib.request.Request]) -> str:\n",
        "    NUM_SECONDS_TIMEOUT = 10\n",
        "\n",
        "    ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH, cafile=certifi.where())\n",
        "    response = urllib.request.urlopen(request, timeout=NUM_SECONDS_TIMEOUT, context=ctx)\n",
        "    data = response.read()\n",
        "    response.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "def read_url_with_retries(request: str, county: County) -> str:\n",
        "    if county in {CountyWithoutCaptcha.ADAMS, CountyWithoutCaptcha.MADISON}:\n",
        "        user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "        headers = {'User-Agent': user_agent}\n",
        "        request = urllib.request.Request(request, headers=headers)\n",
        "\n",
        "    # Try the connection until success or NUM_ATTEMPTS is exceeded\n",
        "    NUM_ATTEMPTS = 4\n",
        "    for _ in range(NUM_ATTEMPTS):\n",
        "        try:\n",
        "            return read_url(request)\n",
        "        except urllib.error.URLError as str_error:\n",
        "            time.sleep(0.5)\n",
        "            print(\"Exception:\", county, str_error)\n",
        "\n",
        "    print(\"Request failed for\", county)\n",
        "    return None"
      ],
      "metadata": {
        "id": "akoAUMqFzDvo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add missing intermediate SSL certificates\n",
        "\n",
        "---\n",
        "\n",
        "This should only be run once per session.\n",
        "\n",
        "According to https://stackoverflow.com/a/64835339, Python cannot automatically download intermediate SSL certificates. \n",
        "\n",
        "For Jackson, this results in an SSL: CERTIFICATE_VERIFY_FAILED error. We add the intermediate certificates found at: https://services.co.jackson.ms.us/jaildocket/_inmateList.php"
      ],
      "metadata": {
        "id": "yTJ_imq6k-BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(certifi.where(), 'a') as global_cert_file:\n",
        "    for filename in os.listdir(CERT_DIR):\n",
        "        with open(CERT_DIR + filename, 'r') as missing_cert_file:\n",
        "            cert_data = missing_cert_file.read()\n",
        "            global_cert_file.write('\\n' + cert_data)"
      ],
      "metadata": {
        "id": "Y2Q6Hac-k62j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counties with Captchas Scraper\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pg782r6e4lKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def county_with_captcha_scraper(county: CountyWithCaptcha, captcha_key: str):\n",
        "    jail_url = jail_captcha_links[county]\n",
        "    jail_record_data = requests.post(\n",
        "        jail_url,\n",
        "        json={'captchaKey': captcha_key}\n",
        "    )\n",
        "    jail_record_data_json = jail_record_data.json()\n",
        "    offender_view_key = jail_record_data_json['offenderViewKey']\n",
        "    num_offenders = len(jail_record_data_json['offenders'])\n",
        "    print(county, \"Number of offenders:\", num_offenders)\n",
        "\n",
        "    def get_inmate_url(arrest_num: str) -> str:\n",
        "        def gen_random_num_with_n_digits(n: int) -> int:\n",
        "            \"\"\"Based on:\n",
        "            https://stackoverflow.com/a/2673399\n",
        "            \"\"\"\n",
        "            range_start = 10 ** (n - 1)\n",
        "            range_end = (10 ** n) - 1\n",
        "            return randint(range_start, range_end)\n",
        "\n",
        "        # Apparently the offender view key is just a random number (and the length doesn't matter)?\n",
        "        # We need an offender view key to make our request\n",
        "        # We use the default length that the website uses, which is 9\n",
        "        LEN_VIEW_KEY = 9\n",
        "        random_offender_view_key = gen_random_num_with_n_digits(LEN_VIEW_KEY)\n",
        "        return f'{jail_url}{arrest_num}/offenderbucket/{random_offender_view_key}'\n",
        "\n",
        "    offender_data = []\n",
        "    cur_num_processed = 0\n",
        "    for offender in jail_record_data_json['offenders']:\n",
        "        arrest_num = offender['arrestNo']\n",
        "        inmate_url = get_inmate_url(arrest_num)\n",
        "        inmate_data = requests.post(\n",
        "            inmate_url,\n",
        "            json={'captchaKey': captcha_key}\n",
        "        )\n",
        "        inmate_data_json = inmate_data.json()\n",
        "\n",
        "        # Add basic data\n",
        "        inmate = {\n",
        "            'Arrest Number': arrest_num,\n",
        "            'Cases': inmate_data_json['cases'],\n",
        "            'Charges': inmate_data_json['charges'],\n",
        "        }\n",
        "\n",
        "        # Add special fields\n",
        "        for field in inmate_data_json['offenderSpecialFields']:\n",
        "            field_name = field['labelText'].strip(':')\n",
        "            inmate[field_name] = field['offenderValue']\n",
        "\n",
        "        offender_data.append(inmate)\n",
        "        cur_num_processed += 1\n",
        "        if cur_num_processed % 50 == 0:\n",
        "            print(county, \"Processed\", cur_num_processed)\n",
        "\n",
        "    filename = get_county_filename(county)\n",
        "    df = pd.DataFrame(offender_data)\n",
        "    df.to_csv(f'{DATA_DIR}{current_date}/{filename}')"
      ],
      "metadata": {
        "id": "6qjLmPVc4qsA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jackson Script\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KQcsHsOo9HuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jackson():\n",
        "    def parse_inmate_card(page_data: BeautifulSoup) -> Dict:\n",
        "        \"\"\"\n",
        "        Return info card and offense card details\n",
        "\n",
        "        Example html scraped of an offense box\n",
        "        [<div class=\"offenseItem\"><p class=\"offenseTitle\">POSSESSION WITH INTENT TO DISTRIBUTE A CONTROLLED SUBSTANCE</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>, <div class=\"offenseItem\"><p class=\"offenseTitle\">POSSESSION OF A CONTROLLED SUBSTANCE - ALL OTHERS</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>, <div class=\"offenseItem\"><p class=\"offenseTitle\">TRAFFICKING IN CONTROLLED SUBSTANCES</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>]\n",
        "\n",
        "        Example html scraped of an info box (the fields are always in the same order)\n",
        "        [<p class=\"ilFieldName\">Black Male</p>, <p class=\"ilFieldName\">170 Pounds</p>, <p class=\"inmateInfo\">5 Ft. 08 In. </p>, <p class=\"inmateInfo\">Brown      Eyes </p>, <p class=\"inmateInfo\">35 Years Old</p>, <p class=\"inmateInfo\">Booking #:NJCADC0000023672</p>, <p class=\"inmateInfo red\">Not Bondable</p>]\n",
        "\n",
        "        \"\"\"\n",
        "        # Parse offenses \n",
        "        # Offenses is a list of dictionaries, where each dictionary contains information about the crime\n",
        "        offenses = []\n",
        "        offense_box = page_data.find('article', class_='ofcard').find_all('div', class_='offenseItem')\n",
        "        for offense in offense_box:\n",
        "            offense_title = offense.find('p', class_='offenseTitle').text\n",
        "            offense_details = offense.find('p', class_='offenseDetails').text.split()\n",
        "            offenses.append({\n",
        "                'chargeDescription': offense_title, \n",
        "                'bondAmount': offense_details[-1][1:],\n",
        "                'crimeType': offense_details[0],\n",
        "            })\n",
        "\n",
        "        def get_formatted_height(height: str) -> str:\n",
        "            return f'''{height[0]}' {height[2]}\"'''\n",
        "\n",
        "        # Parse basic details: height, eye color, age etc.\n",
        "        # Some of the basic details are out of order since some are missing (default missing to empty string)\n",
        "        inmate_info_box = page_data.find_all('p', class_='inmateInfo')\n",
        "        if len(inmate_info_box) == 5:\n",
        "            height_string = inmate_info_box[0].text.split()\n",
        "            height = get_formatted_height(height_string)\n",
        "            eye_color = inmate_info_box[1].text.split()[0]\n",
        "            age = inmate_info_box[2].text.split()[0]\n",
        "        else:\n",
        "            height, eye_color, age = '', '', ''\n",
        "            for detail in inmate_info_box:\n",
        "                if detail.text[-4:] == 'Eyes':\n",
        "                    eye_color = detail.text.split()[0]\n",
        "                elif detail.text[-3:] == 'Old':\n",
        "                    age = detail.text.split()[0]\n",
        "                elif detail.text[-4:] == 'In. ':  # There is a random space in this string\n",
        "                    height_string = detail.text.split()\n",
        "                    height = get_formatted_height(height_string)\n",
        "\n",
        "        # Race and sex format: \"race sex\", where we can have \"not available\" for race and some information can be missing (default missing to empty string)\n",
        "        # Weight format: \"x Pounds\"\n",
        "        inmate_field_box = page_data.find_all('p', class_='ilFieldName')\n",
        "        if len(inmate_field_box) == 2:\n",
        "            race_gender = inmate_field_box[0].text.split()\n",
        "            race = race_gender[0] if race_gender[0] != 'Not' else 'N/A'\n",
        "            sex = race_gender[-1] if race_gender[-1] != 'Available' else 'N/A'\n",
        "            weight = f'{inmate_field_box[1].text.split()[0]} lbs'\n",
        "        else:\n",
        "            weight, sex, race = '', 'N/A', 'N/A'\n",
        "            for detail in inmate_field_box:\n",
        "                if detail.text[-6:] == 'Pounds':\n",
        "                    weight = detail.text.split()[0] + ' lbs'\n",
        "                else:\n",
        "                    if str.lower(detail.text[-3:]) == 'male':\n",
        "                        gender = detail.text.split()[-1]\n",
        "                    if detail.text[:3] != 'Not':\n",
        "                        race = detail.text.split()[0]\n",
        "\n",
        "        return {\n",
        "            'Current Age': age,\n",
        "            'Height': height,\n",
        "            'Weight': weight,\n",
        "            'Eye Color': str.upper(eye_color),\n",
        "            'Race': str.upper(race),\n",
        "            'Sex': str.upper(sex[0]) if sex != 'N/A' else sex,\n",
        "            'Charges': offenses,\n",
        "        }\n",
        "\n",
        "    # Example of inmate in website_data which is a dictionary\n",
        "    # {\n",
        "    #     \"0\":\"421\",\n",
        "    #     \"RowNum\":\"421\",\n",
        "    #     \"1\":\"NJCADC0000026510\",\n",
        "    #     \"Book_Number\":\"NJCADC0000026510\",\n",
        "    #     \"2\":\"STALLWORTH\",\n",
        "    #     \"Name_Last\":\"STALLWORTH\",\n",
        "    #     \"3\":\"DESHAWN\",\n",
        "    #     \"Name_Middle\":\"DESHAWN\",\n",
        "    #     \"4\":\"TREVION\",\n",
        "    #     \"Name_First_MI\":\"TREVION\",\n",
        "    #     \"5\":\"08\\/16\\/2019\",\n",
        "    #     \"BookDate\":\"08\\/16\\/2019\",\n",
        "    #     \"6\":\"08\\/23\\/2019\",\n",
        "    #     \"ArrestDate\":\"08\\/23\\/2019\",\n",
        "    #     \"7\":\"PPD\",\n",
        "    #     \"Arrest_Agency\":\"PPD\",\n",
        "    #     \"8\":\"\",\n",
        "    #     \"Name_Suffix\":\"\",\n",
        "    #     \"9\":\"200978747                \",\n",
        "    #     \"ID_Number\":\"200978747                \"\n",
        "    # }\n",
        "\n",
        "    # Obtain the total count of inmates\n",
        "    # count_html is a bytes string containing the number of inmates\n",
        "    count_url = 'https://services.co.jackson.ms.us/jaildocket/_inmateList.php?Function=count'\n",
        "    count_html = read_url(count_url)\n",
        "    num_offenders = count_html.decode('utf-8')\n",
        "    print(\"Jackson Number of offenders:\", num_offenders)\n",
        "\n",
        "    offender_data = []\n",
        "    cur_num_processed = 0\n",
        "\n",
        "    # While there is a page with inmate data, collect the inmate IDs\n",
        "    page = 1\n",
        "    while True:\n",
        "        url = f'https://services.co.jackson.ms.us/jaildocket/_inmateList.php?Function=list&Page={page}'\n",
        "        website_html = read_url(url)\n",
        "        website_data = json.loads(BeautifulSoup(website_html, 'html.parser').prettify())\n",
        "\n",
        "        # Exit when there is no content on the page\n",
        "        if len(website_data) < 1:\n",
        "            break\n",
        "\n",
        "        # Get details from the inmate card page and the inmate list page\n",
        "        for inmate in website_data:\n",
        "            inmate_id = inmate['ID_Number'].strip()\n",
        "            url = f'https://services.co.jackson.ms.us/jaildocket/inmate/_inmatedetails.php?id={inmate_id}'\n",
        "            inmate_html = read_url(url)\n",
        "            inmate_card_data = BeautifulSoup(inmate_html, 'html.parser')\n",
        "            inmate_info = parse_inmate_card(inmate_card_data)\n",
        "\n",
        "            # Store a row of information on an inmate\n",
        "            inmate = {\n",
        "                'Arrest Number': inmate_id,\n",
        "                'First Name': str.upper(inmate['Name_First_MI']),\n",
        "                'Middle Name': str.upper(inmate['Name_Middle']),\n",
        "                'Last Name': str.upper(inmate['Name_Last']),\n",
        "                'Suffix': str.upper(inmate['Name_Suffix']),\n",
        "                'Arrest Date': inmate['ArrestDate'],\n",
        "                'Booking Date': inmate['BookDate'],\n",
        "                'Arrest Agency': str.upper(inmate['Arrest_Agency']),\n",
        "                'Booking Number': inmate['Book_Number'],\n",
        "            }\n",
        "\n",
        "            # Merge the two dictionaries\n",
        "            inmate.update(inmate_info)\n",
        "\n",
        "            offender_data.append(inmate)\n",
        "            cur_num_processed += 1\n",
        "            if cur_num_processed % 50 == 0:\n",
        "                print(county, \"Processed\", cur_num_processed)\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    filename = get_county_filename(county)\n",
        "    df = pd.DataFrame(offender_data)\n",
        "    df.to_csv(f'{DATA_DIR}{current_date}/{filename}')"
      ],
      "metadata": {
        "id": "ZyTxokJW8yGP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Web Scraper\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "etUaTa_B62nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WebScraperThread(threading.Thread):\n",
        "    def __init__(self, thread_id: int, county: County, captcha_key: str = None):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.thread_id = thread_id\n",
        "        self.county = county\n",
        "        self.captcha_key = captcha_key\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Starting\", self.county)\n",
        "\n",
        "        if self.county in CountyWithCaptcha:\n",
        "            county_with_captcha_scraper(self.county, self.captcha_key)\n",
        "        # elif self.county == CountyWithoutCaptcha.PEARL_RIVER:\n",
        "        #     pearl_river()\n",
        "        # elif self.county == CountyWithoutCaptcha.CLAY:\n",
        "        #     clay()\n",
        "        # elif self.county == CountyWithoutCaptcha.ADAMS:\n",
        "        #     adams()\n",
        "        elif self.county == CountyWithoutCaptcha.JACKSON:\n",
        "            jackson()\n",
        "        # elif self.county == CountyWithoutCaptcha.JONES:\n",
        "        #     jones()\n",
        "        # elif self.county == CountyWithoutCaptcha.MADISON:\n",
        "        #     madison()\n",
        "        # elif self.county == CountyWithoutCaptcha.TUNICA:\n",
        "        #     tunica()\n",
        "        else:\n",
        "            raise Exception(\"County not found:\", self.county)\n",
        "\n",
        "        print(\"Exiting\", self.county, end='\\n\\n')"
      ],
      "metadata": {
        "id": "__7zx5ye7xQG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threads = []\n",
        "thread_id = 1\n",
        "\n",
        "# Get a captcha key for the counties that require captchas\n",
        "is_captcha_matched = False\n",
        "while not is_captcha_matched:\n",
        "    captcha_data = requests.get('https://omsweb.public-safety-cloud.com/jtclientweb/captcha/getnewcaptchaclient')\n",
        "    image = captcha_data.json()['captchaImage']\n",
        "\n",
        "    # To be used later for automated captcha solver\n",
        "    # # Save the image to a file\n",
        "    # import base64\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # img = image.split('base64,')[-1]\n",
        "    # x = base64.decodebytes(img.encode('ascii'))\n",
        "    # with open('captcha.jpg', 'wb') as f:\n",
        "    #     f.write(x)\n",
        "\n",
        "    html = f'<img src=\"{image}\"/>'\n",
        "    IPython.display.display(IPython.display.HTML(html))\n",
        "    user_code = input()\n",
        "\n",
        "    captcha_response_data = requests.post(\n",
        "        'https://omsweb.public-safety-cloud.com/jtclientweb/Captcha/validatecaptcha',\n",
        "        json={'userCode': user_code, 'captchaKey': captcha_data.json()['captchaKey']}\n",
        "    )\n",
        "    is_captcha_matched = captcha_response_data.json()['captchaMatched']\n",
        "    captcha_key = captcha_response_data.json()['captchaKey']\n",
        "\n",
        "    if not is_captcha_matched:\n",
        "        print(\"Incorrect captcha\")\n",
        "\n",
        "for county in CountyWithCaptcha:\n",
        "    thread = WebScraperThread(thread_id, county, captcha_key)\n",
        "    threads.append(thread)\n",
        "    thread_id += 1\n",
        "\n",
        "for county in CountyWithoutCaptcha:\n",
        "    thread = WebScraperThread(thread_id, county)\n",
        "    threads.append(thread)\n",
        "    thread_id += 1\n",
        "\n",
        "for t in threads:\n",
        "    t.start()\n",
        "\n",
        "# Wait for all threads to complete\n",
        "for t in threads:\n",
        "    t.join()\n",
        "\n",
        "print(\"Finished scraping\")"
      ],
      "metadata": {
        "id": "kgGiJkcO652e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e986876-d167-4be2-f55d-c883916eab5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAAAkCAYAAAB/up84AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAOpSURBVGhD7Zk9TuNAGIa3XK20F9gcgpqOblNAxxYUm4KCgjaJhChSrRBCKAFBFIQURAEWShYhoXRQUCAOgXKKvcDsjB3b34xf2zOxx3F+ikeAZ+xI8+T7M19e/r2yFeVhJaRklF5If/MbvL6ozIWQZZKyElIySi1k2WQIMgtp/TgNQOtZWAkxhMpAoHt0KauM5+El+/Pr1IA+G4DnxJFrykJSKOieOMoeHREx53+l9cE5WeO0hyNpPQ6rNQRJoXj7HHa8X2Gb1RBfhvf3Bjv+lJ97fSLvd9k/MPomZmZ8x9rkwFUhAlVK711eRyQIuWetw+9s7XfI1tM92KcPkkLxD9cXoopQCcScdOC6VTSEvLz3JSFwjwIW8rEjiZA4bLAHdM8UICmUXceB9/m4QmYhQ1CYkHGDbUmH3mZ7ipS9D7I/R5AUiry/w5ognRXGFEJ06ogihKepLogAIakAIXLtqEAplJlFh8C4huh1W3pFXRKywy7QnhxQhaj1AUmh0GdZJ0WIJKNxx57JWhJaQh6e1icy1llrjPdkxZchaFIhKC19HrBd3lUhKRTpnrxRhSAMRPikCrnohqlqrduGe/LAlyF+HzgbREglUtxFMW++yfcLkBTKz+2OS7XhBOljMOwF1yn1tBYVRsiI3TbINY7u/OETLyS208o/ZdHocK+JCCBC5BmDF3OdmWPsQClHMMIfWX0ioqZ7gHEpKxI5l+zWIKuYRYhPjq2vQJIxQR3+/IgQ0ZPWDgdwKTXyrY8/8BE7amhEBSWhhkSm+LxrSLT1zbeWICEvbzVJiFfcxVRfY9d0XwooJakHL/YYyRAkCMmSujSFcKROy15xDxFzBhEiirvDJRm3ut63nwqpbt+wq8m6kKGdpiiJQsC6ZurSF8IJ01cRQrz0JEXJtIMgSF3Vs0c+uN14P9E9aaQJ4UyTuoyEhO2vvVlEIrG4m4FSF40UU6Kv4dHgF01daVJkIUFawhHgR0jWl4wm0OKOWl0Trs6yC0n/f4giJpK6POLe/EpCwggABx+0wQVFh09Q3M2KOSZsbwMp06YsS8gRkvSW16VgGS7e/0u0W90UdLquWRKtIVBKMUXcOpMinkfqsoVRUZ9rRKcVvDIpb+paEiFCgBIFPFqoEEEZUtcSCBGDYQ++wypj6lpwId6UHj+Je6mr8rVuDH5edhZKCDo4W6DPz4NSCkEHYAuasiizSl/WhaBDsAH67HlEWwg6BFugz18WrApBz1mRxCv7DwPXVNkZsICKAAAAAElFTkSuQmCC\"/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3VXR\n",
            "StartingStarting FORREST\n",
            "Starting HANCOCK\n",
            " DESOTO\n",
            "Starting HARRISON\n",
            "Starting StartingLAMAR\n",
            " MARION\n",
            "StartingStarting  YAZOO\n",
            "PERRY\n",
            "Starting JACKSON\n",
            "Jackson Number of offenders: 416\n",
            "LAMAR Number of offenders: 91\n",
            "HANCOCK Number of offenders: 246\n",
            "YAZOO Number of offenders: 264\n",
            "DESOTO Number of offenders: 477\n",
            "FORREST Number of offenders: 276\n",
            "PERRY Number of offenders: 37\n",
            "HARRISON Number of offenders: 643\n",
            "MARION Number of offenders: 252\n",
            "JACKSON Processed 50\n",
            "HANCOCK Processed 50\n",
            "Exiting PERRY\n",
            "\n",
            "DESOTO Processed 50\n",
            "MARION Processed 50\n",
            "HARRISON Processed 50\n",
            "FORREST Processed 50\n",
            "LAMAR Processed 50\n",
            "JACKSON Processed 100\n",
            "YAZOO Processed 50\n",
            "HANCOCK Processed 100\n",
            "DESOTO Processed 100\n",
            "MARION Processed 100\n",
            "Exiting LAMAR\n",
            "\n",
            "FORREST Processed 100\n",
            "HARRISON Processed 100\n",
            "JACKSON Processed 150\n",
            "HANCOCK Processed 150\n",
            "DESOTO Processed 150\n",
            "JACKSON Processed 200\n",
            "MARION Processed 150\n",
            "FORREST Processed 150\n",
            "HARRISON Processed 150\n",
            "YAZOO Processed 100\n",
            "HANCOCK Processed 200\n",
            "JACKSON Processed 250\n",
            "DESOTO Processed 200\n",
            "MARION Processed 200\n",
            "HARRISON Processed 200\n",
            "FORREST Processed 200\n",
            "Exiting HANCOCK\n",
            "\n",
            "JACKSON Processed 300\n",
            "DESOTO Processed 250\n",
            "YAZOO Processed 150\n",
            "MARION Processed 250\n",
            "HARRISON Processed 250\n",
            "Exiting MARION\n",
            "\n",
            "FORREST Processed 250\n",
            "JACKSON Processed 350\n",
            "Exiting FORREST\n",
            "\n",
            "DESOTO Processed 300\n",
            "JACKSON Processed 400\n",
            "HARRISON Processed 300\n",
            "Exiting JACKSON\n",
            "\n",
            "YAZOO Processed 200\n",
            "DESOTO Processed 350\n",
            "HARRISON Processed 350\n",
            "DESOTO Processed 400\n",
            "YAZOO Processed 250\n",
            "HARRISON Processed 400\n",
            "Exiting YAZOO\n",
            "\n",
            "DESOTO Processed 450\n",
            "Exiting DESOTO\n",
            "\n",
            "HARRISON Processed 450\n",
            "HARRISON Processed 500\n",
            "HARRISON Processed 550\n",
            "HARRISON Processed 600\n",
            "Exiting HARRISON\n",
            "\n",
            "Finished scraping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F_5rcmU_Q_ok"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}