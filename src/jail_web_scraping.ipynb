{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jail_web_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Links\n",
        "\n",
        "---\n",
        "\n",
        "Harrison - https://omsweb.public-safety-cloud.com/jtclientweb/jailtracker/index/HARRISON_COUNTY_JAIL_MS\n",
        "\n",
        "Yazoo - https://omsweb.public-safety-cloud.com/jtclientweb/jailtracker/index/Yazoo_County_MS/"
      ],
      "metadata": {
        "id": "fvO3wm680ICC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Dict\n",
        "from enum import Enum, unique\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "import urllib\n",
        "import requests\n",
        "import ssl\n",
        "import certifi\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import threading\n",
        "import IPython\n",
        "\n",
        "# Used for debugging; pretty print JSON strings\n",
        "import json"
      ],
      "metadata": {
        "id": "OS7Po5Gqy7tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhqLGdsry29O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da11324-f0d8-4904-f44f-d43ae708b115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/'):\n",
        "    raise Exception(\"ERROR: Mount Google Drive before continuing!\")\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/Data Science for Social Good - Spring 2022/data/'\n",
        "\n",
        "# Define directory that contains intermediate SSL certificates\n",
        "CERT_DIR = BASE_DIR + 'certificates/'\n",
        "\n",
        "# Define directories to save data\n",
        "SCRAPE_DIR = BASE_DIR + 'scraped_files/'\n",
        "DATA_DIR = SCRAPE_DIR + 'DATA/'\n",
        "\n",
        "CURRENT_DATE = datetime.now(timezone('US/Eastern')).strftime('%m-%d-%Y')\n",
        "\n",
        "# Create all directories on the given paths if needed\n",
        "os.makedirs(f'{DATA_DIR}{CURRENT_DATE}', exist_ok=True)\n",
        "print(\"Date used for scraping:\", CURRENT_DATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9MsX6May6ms",
        "outputId": "be7ad5dc-7e6c-4f5e-b8c5-9969daf6430d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date used for scraping: 03-22-2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions and Classes\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fR8wSuIfzlDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@unique\n",
        "class CountyWithCaptcha(Enum):\n",
        "    DESOTO = 'DeSoto'\n",
        "    FORREST = 'Forrest'\n",
        "    HANCOCK = 'Hancock'\n",
        "    HARRISON = 'Harrison'\n",
        "    LAMAR = 'Lamar'\n",
        "    MARION = 'Marion'\n",
        "    PERRY = 'Perry'\n",
        "    YAZOO = 'Yazoo'\n",
        "\n",
        "    # Return Name, rather than CountyWithCaptcha.Name\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "@unique\n",
        "class CountyWithoutCaptcha(Enum):\n",
        "    # The commented out counties only have the total bond, not bond by crime\n",
        "    PEARL_RIVER = 'PearlRiver'\n",
        "    JACKSON = 'Jackson'\n",
        "    MADISON = 'Madison'\n",
        "    # ADAMS = 'Adams'\n",
        "    # CLAY = 'Clay'\n",
        "    # JONES = 'Jones'\n",
        "    # TUNICA = 'Tunica'\n",
        "\n",
        "    # Return Name, rather than CountyWithoutCaptcha.Name\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "# Define a custom type to pass into functions\n",
        "County = Union[CountyWithCaptcha, CountyWithoutCaptcha]\n",
        "\n",
        "\n",
        "def get_county_filename(county: County) -> str:\n",
        "    return f'{str(CURRENT_DATE)}_{county.value}.csv'"
      ],
      "metadata": {
        "id": "6a2YyDv2zpw4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jail_links = {\n",
        "    CountyWithCaptcha.DESOTO: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/DeSoto_County_MS/',\n",
        "    CountyWithCaptcha.FORREST: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Forrest_County_MS/',\n",
        "    CountyWithCaptcha.HANCOCK: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/HANCOCK_COUNTY_MS/',\n",
        "    CountyWithCaptcha.HARRISON: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/HARRISON_COUNTY_JAIL_MS/',\n",
        "    CountyWithCaptcha.LAMAR: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Lamar_County_MS/',\n",
        "    CountyWithCaptcha.MARION: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Marion_County_MS/',\n",
        "    CountyWithCaptcha.PERRY: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Perry_County_MS/',\n",
        "    CountyWithCaptcha.YAZOO: 'https://omsweb.public-safety-cloud.com/jtclientweb/Offender/Yazoo_County_MS/',\n",
        "    CountyWithoutCaptcha.PEARL_RIVER: 'https://www.pearlrivercounty.net/sheriff/files/',\n",
        "    CountyWithoutCaptcha.MADISON: 'https://mydcstraining.com/agencyinfo/MS/4360/inmate/',\n",
        "}\n"
      ],
      "metadata": {
        "id": "1FnFWhPZ4NQx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_url(request: Union[str, urllib.request.Request]) -> str:\n",
        "    NUM_SECONDS_TIMEOUT = 10\n",
        "\n",
        "    ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH, cafile=certifi.where())\n",
        "    response = urllib.request.urlopen(request, timeout=NUM_SECONDS_TIMEOUT, context=ctx)\n",
        "    data = response.read()\n",
        "    response.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "def read_url_with_retries(url: str, use_headers: bool = False) -> str:\n",
        "    if use_headers:\n",
        "        user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "        headers = {'User-Agent': user_agent}\n",
        "        request = urllib.request.Request(url, headers=headers)\n",
        "    else:\n",
        "        request = url\n",
        "\n",
        "    # Try the connection until success or NUM_ATTEMPTS is exceeded\n",
        "    NUM_ATTEMPTS = 5\n",
        "    for _ in range(NUM_ATTEMPTS):\n",
        "        try:\n",
        "            return read_url(request)\n",
        "        except urllib.error.URLError as str_error:\n",
        "            time.sleep(0.5)\n",
        "            print(\"Exception:\", url, str_error)\n",
        "\n",
        "    print(\"Request failed for\", url)\n",
        "    return None"
      ],
      "metadata": {
        "id": "akoAUMqFzDvo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add missing intermediate SSL certificates\n",
        "\n",
        "---\n",
        "\n",
        "This should only be run once per session.\n",
        "\n",
        "According to https://stackoverflow.com/a/64835339, Python cannot automatically download intermediate SSL certificates. \n",
        "\n",
        "For Jackson, this results in an SSL: CERTIFICATE_VERIFY_FAILED error. We add the intermediate certificates found at: https://services.co.jackson.ms.us/jaildocket/_inmateList.php"
      ],
      "metadata": {
        "id": "yTJ_imq6k-BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(certifi.where(), 'a') as global_cert_file:\n",
        "    for filename in os.listdir(CERT_DIR):\n",
        "        with open(CERT_DIR + filename, 'r') as missing_cert_file:\n",
        "            cert_data = missing_cert_file.read()\n",
        "            global_cert_file.write('\\n' + cert_data)"
      ],
      "metadata": {
        "id": "Y2Q6Hac-k62j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counties with Captchas Scraper\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pg782r6e4lKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def county_with_captcha_scraper(county: CountyWithCaptcha, captcha_key: str):\n",
        "    jail_url = jail_links[county]\n",
        "    jail_record_data = requests.post(\n",
        "        jail_url,\n",
        "        json={'captchaKey': captcha_key}\n",
        "    )\n",
        "    jail_record_data_json = jail_record_data.json()\n",
        "    offender_view_key = jail_record_data_json['offenderViewKey']\n",
        "    num_offenders = len(jail_record_data_json['offenders'])\n",
        "    print(county, \"Number of offenders:\", num_offenders)\n",
        "\n",
        "    def get_inmate_url(arrest_num: str) -> str:\n",
        "        def gen_random_num_with_n_digits(n: int) -> int:\n",
        "            \"\"\"Based on:\n",
        "            https://stackoverflow.com/a/2673399\n",
        "            \"\"\"\n",
        "            range_start = 10 ** (n - 1)\n",
        "            range_end = (10 ** n) - 1\n",
        "            return randint(range_start, range_end)\n",
        "\n",
        "        # Apparently the offender view key is just a random number (and the length doesn't matter)?\n",
        "        # We need an offender view key to make our request\n",
        "        # We use the default length that the website uses, which is 9\n",
        "        LEN_VIEW_KEY = 9\n",
        "        random_offender_view_key = gen_random_num_with_n_digits(LEN_VIEW_KEY)\n",
        "        return f'{jail_url}{arrest_num}/offenderbucket/{random_offender_view_key}'\n",
        "\n",
        "    offender_data = []\n",
        "    cur_num_processed = 0\n",
        "    for offender in jail_record_data_json['offenders']:\n",
        "        arrest_num = offender['arrestNo']\n",
        "        inmate_url = get_inmate_url(arrest_num)\n",
        "        inmate_data = requests.post(\n",
        "            inmate_url,\n",
        "            json={'captchaKey': captcha_key}\n",
        "        )\n",
        "        inmate_data_json = inmate_data.json()\n",
        "\n",
        "        # Add basic data\n",
        "        inmate = {\n",
        "            'Arrest Number': arrest_num,\n",
        "            'Cases': inmate_data_json['cases'],\n",
        "            'Charges': inmate_data_json['charges'],\n",
        "        }\n",
        "\n",
        "        # Add special fields\n",
        "        for field in inmate_data_json['offenderSpecialFields']:\n",
        "            field_name = field['labelText'].strip(':')\n",
        "            inmate[field_name] = field['offenderValue']\n",
        "\n",
        "        offender_data.append(inmate)\n",
        "        cur_num_processed += 1\n",
        "        if cur_num_processed % 50 == 0:\n",
        "            print(county, \"Processed\", cur_num_processed)\n",
        "\n",
        "    filename = get_county_filename(county)\n",
        "    df = pd.DataFrame(offender_data)\n",
        "    df.to_csv(f'{DATA_DIR}{CURRENT_DATE}/{filename}', index=False)"
      ],
      "metadata": {
        "id": "6qjLmPVc4qsA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jackson Script\n",
        "\n",
        "---\n",
        "\n",
        "Occasionally, Jackson will time out. We aren't sure what causes this, but the issue is usually gone when rerunning the scraper later in the day."
      ],
      "metadata": {
        "id": "KQcsHsOo9HuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jackson():\n",
        "    def parse_inmate_card(page_data: BeautifulSoup) -> Dict:\n",
        "        \"\"\"\n",
        "        Return info card and offense card details.\n",
        "\n",
        "        Example html scraped of an offense box:\n",
        "        [<div class=\"offenseItem\"><p class=\"offenseTitle\">POSSESSION WITH INTENT TO DISTRIBUTE A CONTROLLED SUBSTANCE</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>, <div class=\"offenseItem\"><p class=\"offenseTitle\">POSSESSION OF A CONTROLLED SUBSTANCE - ALL OTHERS</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>, <div class=\"offenseItem\"><p class=\"offenseTitle\">TRAFFICKING IN CONTROLLED SUBSTANCES</p><p class=\"offenseDetails\">Felony - Bond: $0.00</p></div>]\n",
        "\n",
        "        Example html scraped of an info box (the fields are always in the same order):\n",
        "        [<p class=\"ilFieldName\">Black Male</p>, <p class=\"ilFieldName\">170 Pounds</p>, <p class=\"inmateInfo\">5 Ft. 08 In. </p>, <p class=\"inmateInfo\">Brown      Eyes </p>, <p class=\"inmateInfo\">35 Years Old</p>, <p class=\"inmateInfo\">Booking #:NJCADC0000023672</p>, <p class=\"inmateInfo red\">Not Bondable</p>]\n",
        "\n",
        "        \"\"\"\n",
        "        # Parse offenses \n",
        "        # Offenses is a list of dictionaries, where each dictionary contains information about the crime\n",
        "        offenses = []\n",
        "        offense_box = page_data.find('article', class_='ofcard').find_all('div', class_='offenseItem')\n",
        "        for offense in offense_box:\n",
        "            offense_title = offense.find('p', class_='offenseTitle').text\n",
        "            offense_details = offense.find('p', class_='offenseDetails').text.split()\n",
        "            offenses.append({\n",
        "                'chargeDescription': offense_title, \n",
        "                'bondAmount': offense_details[-1][1:],\n",
        "                'crimeType': offense_details[0],\n",
        "            })\n",
        "\n",
        "        def get_formatted_height(height: str) -> str:\n",
        "            \"\"\"Return height as:\n",
        "            {feet}' {inches}\"\n",
        "            \"\"\"\n",
        "            return f'''{height[0]}' {height[2]}\"'''\n",
        "\n",
        "        # Parse basic details: height, eye color, age etc.\n",
        "        # Some of the basic details are out of order since some are missing (default missing to empty string)\n",
        "        inmate_info_box = page_data.find_all('p', class_='inmateInfo')\n",
        "        if len(inmate_info_box) == 5:\n",
        "            height_string = inmate_info_box[0].text.split()\n",
        "            height = get_formatted_height(height_string)\n",
        "            eye_color = inmate_info_box[1].text.split()[0]\n",
        "            age = inmate_info_box[2].text.split()[0]\n",
        "        else:\n",
        "            height, eye_color, age = '', '', ''\n",
        "            for detail in inmate_info_box:\n",
        "                if detail.text[-4:] == 'Eyes':\n",
        "                    eye_color = detail.text.split()[0]\n",
        "                elif detail.text[-3:] == 'Old':\n",
        "                    age = detail.text.split()[0]\n",
        "                elif detail.text[-4:] == 'In. ':  # There is a random space in this string\n",
        "                    height_string = detail.text.split()\n",
        "                    height = get_formatted_height(height_string)\n",
        "\n",
        "        # Race and sex format: \"race sex\", where we can have \"not available\" for race and some information can be missing (default missing to empty string)\n",
        "        # Weight format: \"x Pounds\"\n",
        "        inmate_field_box = page_data.find_all('p', class_='ilFieldName')\n",
        "        if len(inmate_field_box) == 2:\n",
        "            race_gender = inmate_field_box[0].text.split()\n",
        "            race = race_gender[0] if race_gender[0] != 'Not' else 'N/A'\n",
        "            sex = race_gender[-1] if race_gender[-1] != 'Available' else 'N/A'\n",
        "            weight = f'{inmate_field_box[1].text.split()[0]} lbs'\n",
        "        else:\n",
        "            weight, sex, race = '', 'N/A', 'N/A'\n",
        "            for detail in inmate_field_box:\n",
        "                if detail.text[-6:] == 'Pounds':\n",
        "                    weight = detail.text.split()[0] + ' lbs'\n",
        "                else:\n",
        "                    if str.lower(detail.text[-3:]) == 'male':\n",
        "                        gender = detail.text.split()[-1]\n",
        "                    if detail.text[:3] != 'Not':\n",
        "                        race = detail.text.split()[0]\n",
        "\n",
        "        return {\n",
        "            'Current Age': age,\n",
        "            'Height': height,\n",
        "            'Weight': weight,\n",
        "            'Eye Color': eye_color,\n",
        "            'Race': race,\n",
        "            'Sex': sex,\n",
        "            'Charges': offenses,\n",
        "        }\n",
        "\n",
        "    # Example of inmate in website_data which is a dictionary\n",
        "    # {\n",
        "    #     \"0\":\"421\",\n",
        "    #     \"RowNum\":\"421\",\n",
        "    #     \"1\":\"NJCADC0000026510\",\n",
        "    #     \"Book_Number\":\"NJCADC0000026510\",\n",
        "    #     \"2\":\"STALLWORTH\",\n",
        "    #     \"Name_Last\":\"STALLWORTH\",\n",
        "    #     \"3\":\"DESHAWN\",\n",
        "    #     \"Name_Middle\":\"DESHAWN\",\n",
        "    #     \"4\":\"TREVION\",\n",
        "    #     \"Name_First_MI\":\"TREVION\",\n",
        "    #     \"5\":\"08\\/16\\/2019\",\n",
        "    #     \"BookDate\":\"08\\/16\\/2019\",\n",
        "    #     \"6\":\"08\\/23\\/2019\",\n",
        "    #     \"ArrestDate\":\"08\\/23\\/2019\",\n",
        "    #     \"7\":\"PPD\",\n",
        "    #     \"Arrest_Agency\":\"PPD\",\n",
        "    #     \"8\":\"\",\n",
        "    #     \"Name_Suffix\":\"\",\n",
        "    #     \"9\":\"200978747                \",\n",
        "    #     \"ID_Number\":\"200978747                \"\n",
        "    # }\n",
        "\n",
        "    # Obtain the total count of inmates\n",
        "    # count_html is a bytes string containing the number of inmates\n",
        "    count_url = 'https://services.co.jackson.ms.us/jaildocket/_inmateList.php?Function=count'\n",
        "    count_html = read_url_with_retries(count_url)\n",
        "    num_offenders = count_html.decode('utf-8')\n",
        "    print(\"Jackson Number of offenders:\", num_offenders)\n",
        "\n",
        "    offender_data = []\n",
        "    cur_num_processed = 0\n",
        "\n",
        "    # While there is a page with inmate data, collect the inmate IDs\n",
        "    page = 1\n",
        "    while True:\n",
        "        url = f'https://services.co.jackson.ms.us/jaildocket/_inmateList.php?Function=list&Page={page}'\n",
        "        website_html = read_url_with_retries(url)\n",
        "        website_data = json.loads(BeautifulSoup(website_html, 'html.parser').prettify())\n",
        "\n",
        "        # Exit when there is no content on the page\n",
        "        if len(website_data) < 1:\n",
        "            break\n",
        "\n",
        "        # Get details from the inmate card page and the inmate list page\n",
        "        for inmate in website_data:\n",
        "            inmate_id = inmate['ID_Number'].strip()\n",
        "            url = f'https://services.co.jackson.ms.us/jaildocket/inmate/_inmatedetails.php?id={inmate_id}'\n",
        "            inmate_html = read_url_with_retries(url)\n",
        "            inmate_card_data = BeautifulSoup(inmate_html, 'html.parser')\n",
        "            inmate_info = parse_inmate_card(inmate_card_data)\n",
        "\n",
        "            # Store a row of information on an inmate\n",
        "            inmate = {\n",
        "                'Arrest Number': inmate_id,\n",
        "                'First Name': str.upper(inmate['Name_First_MI']),\n",
        "                'Middle Name': str.upper(inmate['Name_Middle']),\n",
        "                'Last Name': str.upper(inmate['Name_Last']),\n",
        "                'Suffix': str.upper(inmate['Name_Suffix']),\n",
        "                'Arrest Date': inmate['ArrestDate'],\n",
        "                'Booking Date': inmate['BookDate'],\n",
        "                'Arrest Agency': str.upper(inmate['Arrest_Agency']),\n",
        "                'Booking Number': inmate['Book_Number'],\n",
        "            }\n",
        "\n",
        "            # Merge the two dictionaries\n",
        "            inmate.update(inmate_info)\n",
        "\n",
        "            offender_data.append(inmate)\n",
        "            cur_num_processed += 1\n",
        "            if cur_num_processed % 50 == 0:\n",
        "                print(county, \"Processed\", cur_num_processed)\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    filename = get_county_filename(county)\n",
        "    df = pd.DataFrame(offender_data)\n",
        "    df.to_csv(f'{DATA_DIR}{CURRENT_DATE}/{filename}', index=False)"
      ],
      "metadata": {
        "id": "ZyTxokJW8yGP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PEARLRIVER_MADISON COMBO WOMBO"
      ],
      "metadata": {
        "id": "s6Cto76ZDLjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pearlriver_madison(county: CountyWithoutCaptcha):\n",
        "    base_url = jail_links[county]\n",
        "    all_url = base_url + 'ICURRENT.HTM'\n",
        "\n",
        "    def get_list_of_inmates_url(url):\n",
        "        detail_urls = []\n",
        "        web_html = read_url_with_retries(url, True)\n",
        "        soup = BeautifulSoup(web_html, 'html.parser')\n",
        "        suffix_set = soup.findAll('a')\n",
        "        for inmate_entry in suffix_set:\n",
        "            detail_urls.append(base_url + inmate_entry['href'])\n",
        "        return detail_urls\n",
        "\n",
        "    def get_info(url):\n",
        "        inmate_detail = {}\n",
        "        web_html = read_url_with_retries(url, True)\n",
        "        soup = BeautifulSoup(web_html, 'html.parser')\n",
        "\n",
        "        # Check if the link has content (check name is the fastest way)\n",
        "        if soup.find('b', text='Name: ') == None:\n",
        "            return None\n",
        "        full_name = soup.find('b', text='Name: ').next_sibling.split()\n",
        "\n",
        "        inmate_detail['First Name'] = full_name[0]\n",
        "        inmate_detail['Last Name'] = full_name[len(full_name) - 1]\n",
        "\n",
        "        # Middle name, changing it from an array to just a string\n",
        "        full_mid = '' if len(full_name[1:len(full_name) - 1]) == 0 else full_name[1:len(full_name) - 1]\n",
        "        tmp_mid = ''\n",
        "        for i in full_mid:\n",
        "            tmp_mid += i\n",
        "        inmate_detail['Middle Name'] = tmp_mid\n",
        "\n",
        "        inmate_detail['Current Age'] = soup.find('b', text='AGE:').next_sibling.strip()\n",
        "\n",
        "        # Add the ' for the height (page shows 600, making it 6'00)\n",
        "        height = soup.find('b', text='HGT: ').next_sibling.strip()\n",
        "        inmate_detail['Height'] = height[0] + ' \\'' + height[1:]\n",
        "        inmate_detail['Weight'] = soup.find('b', text='WGT: ').next_sibling.strip()\n",
        "        inmate_detail['Race'] = soup.find('b', text='RACE: ').next_sibling.strip()\n",
        "        inmate_detail['Sex'] = soup.find('b', text='SEX: ').next_sibling.strip()\n",
        "        inmate_detail['Hair'] = soup.find('b', text='HAIR: ').next_sibling.strip()\n",
        "        inmate_detail['Eye'] = soup.find('b', text='EYE: ').next_sibling.strip()\n",
        "\n",
        "        # A lot of inconsistency with this, so I just took it out\n",
        "        # inmate_detail['Case Number'] = soup.find('b', text=' - Case#:').next_sibling.strip()\n",
        "\n",
        "        inmate_detail['Booking Date'] = soup.find('b', text='INTAKE DATE: ').next_sibling.strip() + ' ' + soup.find('b',text='TIME:').next_sibling.strip()\n",
        "        inmate_detail['Intake_num'] = soup.find('b', text='INTAKE #: ').next_sibling.strip()\n",
        "        inmate_detail['Arresting Agency'] = soup.find('b', text='ARRESTING AGENCY: ').next_sibling.strip()\n",
        "\n",
        "        charge_list_tag = soup.find('table', {'width': '100%', 'align': 'center', 'cellspacing': '2'}).findAll('tr')[2:]\n",
        "        inmate_detail['Charges'] = ''\n",
        "        # Append each charges into an dict\n",
        "        for charge in charge_list_tag:\n",
        "            bail_info = {}\n",
        "            charge_info = charge.findAll('td')\n",
        "\n",
        "            # Freaking weird symbol that wont go away with decode >:(\n",
        "            bail_info['charge_description'] = charge_info[0].contents[0].strip().replace('ã', ' ')\n",
        "            bail_info['charge_court'] = charge_info[1].contents[0].strip().replace('ã', ' ')\n",
        "            if len(charge_info[2]) == 0:\n",
        "                bail_info['charge_bond_amount'] = 0\n",
        "            else:\n",
        "                bail_info['charge_bond_amount'] = charge_info[2].contents[0].strip()\n",
        "\n",
        "            inmate_detail['Charges'] = bail_info\n",
        "\n",
        "        return inmate_detail\n",
        "\n",
        "    all_info = pd.DataFrame()\n",
        "    detail_urls = get_list_of_inmates_url(all_url)\n",
        "    \n",
        "    for inmate_url in detail_urls:\n",
        "        info_arr = get_info(inmate_url)\n",
        "        if info_arr != None:\n",
        "            all_info = all_info.append(info_arr, ignore_index=True)\n",
        "    \n",
        "    filename = get_county_filename(county)\n",
        "    all_info.to_csv(f'{DATA_DIR}{CURRENT_DATE}/{filename}', index=False)"
      ],
      "metadata": {
        "id": "LJ4G7zXWDYS7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Web Scraper\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "etUaTa_B62nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WebScraperThread(threading.Thread):\n",
        "    def __init__(self, thread_id: int, county: County, captcha_key: str = None):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.thread_id = thread_id\n",
        "        self.county = county\n",
        "        self.captcha_key = captcha_key\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Starting\", self.county, flush=True)\n",
        "\n",
        "        if self.county in CountyWithCaptcha:\n",
        "            county_with_captcha_scraper(self.county, self.captcha_key)\n",
        "        # elif self.county == CountyWithoutCaptcha.PEARL_RIVER:\n",
        "        #     pearl_river()\n",
        "        # elif self.county == CountyWithoutCaptcha.CLAY:\n",
        "        #     clay()\n",
        "        # elif self.county == CountyWithoutCaptcha.ADAMS:\n",
        "        #     adams()\n",
        "        elif self.county == CountyWithoutCaptcha.JACKSON:\n",
        "            jackson()\n",
        "        # elif self.county == CountyWithoutCaptcha.JONES:\n",
        "        #     jones()\n",
        "        # elif self.county == CountyWithoutCaptcha.MADISON:\n",
        "        #     madison()\n",
        "        # elif self.county == CountyWithoutCaptcha.TUNICA:\n",
        "        #     tunica()\n",
        "        else:\n",
        "            raise Exception(\"County not found:\", self.county, flush=True)\n",
        "\n",
        "        print(\"Exiting\", self.county, end='\\n\\n', flush=True)"
      ],
      "metadata": {
        "id": "__7zx5ye7xQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threads = []\n",
        "thread_id = 1\n",
        "\n",
        "# Get a captcha key for the counties that require captchas\n",
        "is_captcha_matched = False\n",
        "while not is_captcha_matched:\n",
        "    captcha_data = requests.get('https://omsweb.public-safety-cloud.com/jtclientweb/captcha/getnewcaptchaclient')\n",
        "    image = captcha_data.json()['captchaImage']\n",
        "\n",
        "    # To be used later for automated captcha solver\n",
        "    # # Save the image to a file\n",
        "    # import base64\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # img = image.split('base64,')[-1]\n",
        "    # x = base64.decodebytes(img.encode('ascii'))\n",
        "    # with open('captcha.jpg', 'wb') as f:\n",
        "    #     f.write(x)\n",
        "\n",
        "    html = f'<img src=\"{image}\"/>'\n",
        "    IPython.display.display(IPython.display.HTML(html))\n",
        "    user_code = input()\n",
        "\n",
        "    captcha_response_data = requests.post(\n",
        "        'https://omsweb.public-safety-cloud.com/jtclientweb/Captcha/validatecaptcha',\n",
        "        json={'userCode': user_code, 'captchaKey': captcha_data.json()['captchaKey']}\n",
        "    )\n",
        "    is_captcha_matched = captcha_response_data.json()['captchaMatched']\n",
        "    captcha_key = captcha_response_data.json()['captchaKey']\n",
        "\n",
        "    if not is_captcha_matched:\n",
        "        print(\"Incorrect captcha\")\n",
        "\n",
        "for county in CountyWithCaptcha:\n",
        "    thread = WebScraperThread(thread_id, county, captcha_key)\n",
        "    threads.append(thread)\n",
        "    thread_id += 1\n",
        "\n",
        "for county in CountyWithoutCaptcha:\n",
        "    thread = WebScraperThread(thread_id, county)\n",
        "    threads.append(thread)\n",
        "    thread_id += 1\n",
        "\n",
        "for t in threads:\n",
        "    t.start()\n",
        "\n",
        "# Wait for all threads to complete\n",
        "for t in threads:\n",
        "    t.join()\n",
        "\n",
        "print(\"Finished scraping\")"
      ],
      "metadata": {
        "id": "kgGiJkcO652e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d767676a-e7dd-4b75-bc56-646d11339f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAAAkCAYAAAB/up84AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAMuSURBVGhD7ZlPS1tBEMD7HVrwVmih0oPeSr9Fe4gH6T1fIIcgGqi3XgMKKRSMoBEULyKKgmAMVMihEAJectCc8x2E6fuf2dnpe8k6Gzd2D7/Lzu57sL/MzO7Lq9HjADzu4IU4hhfiGF6IY3ghjuGFOIYX4hiZkPevlwv5tviLcALX6GGepxMJ4TbfFPoCz3TwJWt4BVWcCZu/o3FOgCnaOz0RUwlR6JyM42QOJ8AU5Z3/AVaETAK3+aZwz8dsf/qowc1zATEh1b2ePkcAToAp8yDFWMj1Joo/02kLby4ngIN7ziz4+e4zO04xEqLIWL2COxSzBd78PLi1EcM6bC0swfeF5YQKdLl5FghlyArhsCiC22gObi3HoFlCIlRabX6NJPJCogzpweEqGguw0Te4jQ/h5k6ElhkU+5liSQgzvngAh0OyltJuwYc3PyamKvyL7a4vwVazMx5rVzQptrPEnpCAu70DJCRg0tKliWnBWRLr7TTU2JdT6OG1xhxBa/1IG6clzKWyZdDUTUtXG6p405GQECqltPMHrRVGKWMluCjKcgEsCmHik5SuAiGjh1Mo5cUlUYTM5rRlV0jA9KWrQEhhXBDUR5T+YsQ5XL4tQ1NjA26jH2kXblfKmZDxOA8rRNts9uKnl658KQUbTjNErI/ohI1eNjuolDr0yZxUSJ6MEEWILoJCxGilK6beQXMyiBCy4bSHSJ+2xgSNPipXwr3jpo6ElOHyRo3f725kUvA4hS9ZVvi3EFVGAxoPdK0caXY8vVRR4tKUSVnZh3sl5roQjrU2s06QpHfIy0hQsgT1inC8du64EKVkUVk2siQpVey9pCJUvkiWBBLC8X4tLmFzJISJi0rpwMVXXkYsSu7oG/YKNUvChh83+TkTMoCzNRQPkLoc5n1cjGBFmaIfg493u1l8roWI9BTm2xVFuqeEJUrNEn4ex8vOkMIvvTHi37KG+3CcClFOW8W4I0T7dGL3+GubNEvofaSI2QnJ+dqry7B5MZwR0RFYv7EXYV/IlP+HSDXyZye5e7CxHGZYsl4y6clqnBH92nTNPMULEQDfPeKeEQgyyI7R4wD+AoJNLmtXuvxqAAAAAElFTkSuQmCC\"/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RB2y\n",
            "StartingStarting  FORREST\n",
            "StartingDESOTO\n",
            "Starting HARRISON\n",
            "Starting LAMAR\n",
            " Starting MARION\n",
            "HANCOCK\n",
            "Starting PERRY\n",
            "StartingStarting JACKSON YAZOO\n",
            "\n",
            "Jackson Number of offenders: 423\n",
            "PERRY Number of offenders: 35\n",
            "LAMAR Number of offenders: 91\n",
            "HANCOCK Number of offenders: 259\n",
            "YAZOO Number of offenders: 258\n",
            "HARRISON Number of offenders: 650\n",
            "DESOTO Number of offenders: 492\n",
            "MARION Number of offenders: 246\n",
            "FORREST Number of offenders: 272\n",
            "JACKSON Processed 50\n",
            "JACKSON Processed 100\n",
            "Exiting PERRY\n",
            "\n",
            "FORREST Processed 50\n",
            "HANCOCK Processed 50\n",
            "MARION Processed 50\n",
            "HARRISON Processed 50\n",
            "DESOTO Processed 50\n",
            "YAZOO Processed 50\n",
            "JACKSON Processed 150\n",
            "LAMAR Processed 50\n",
            "JACKSON Processed 200\n",
            "FORREST Processed 100\n",
            "JACKSON Processed 250\n",
            "MARION Processed 100\n",
            "HANCOCK Processed 100\n",
            "HARRISON Processed 100\n",
            "DESOTO Processed 100\n",
            "YAZOO Processed 100\n",
            "Exiting LAMAR\n",
            "\n",
            "JACKSON Processed 300\n",
            "JACKSON Processed 350\n",
            "FORREST Processed 150\n",
            "MARION Processed 150\n",
            "HANCOCK Processed 150\n",
            "HARRISON Processed 150\n",
            "JACKSON Processed 400\n",
            "YAZOO Processed 150\n",
            "DESOTO Processed 150\n",
            "Exiting JACKSON\n",
            "\n",
            "FORREST Processed 200\n",
            "MARION Processed 200\n",
            "HANCOCK Processed 200\n",
            "YAZOO Processed 200\n",
            "HARRISON Processed 200\n",
            "DESOTO Processed 200\n",
            "FORREST Processed 250\n",
            "Exiting MARION\n",
            "\n",
            "HANCOCK Processed 250\n",
            "Exiting HANCOCK\n",
            "\n",
            "Exiting FORREST\n",
            "\n",
            "YAZOO Processed 250\n",
            "HARRISON Processed 250\n",
            "DESOTO Processed 250\n",
            "Exiting YAZOO\n",
            "\n",
            "DESOTO Processed 300\n",
            "HARRISON Processed 300\n",
            "DESOTO Processed 350\n",
            "HARRISON Processed 350\n",
            "DESOTO Processed 400\n",
            "HARRISON Processed 400\n",
            "DESOTO Processed 450\n",
            "HARRISON Processed 450\n",
            "Exiting DESOTO\n",
            "\n",
            "HARRISON Processed 500\n",
            "HARRISON Processed 550\n",
            "HARRISON Processed 600\n",
            "HARRISON Processed 650\n",
            "Exiting HARRISON\n",
            "\n",
            "Finished scraping\n"
          ]
        }
      ]
    }
  ]
}