{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clean_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "from pytz import timezone"
      ],
      "metadata": {
        "id": "bkMKEM0VXs-7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdlv6fdjXIOp",
        "outputId": "1a1302a2-7f93-4aaa-e382-6e40d3d817d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/'):\n",
        "    raise Exception(\"ERROR: Mount Google Drive before continuing!\")\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/Data Science for Social Good - Spring 2022/data/'\n",
        "SCRAPE_DIR = BASE_DIR + 'scraped_files/'\n",
        "DATA_DIR = SCRAPE_DIR + 'DATA/'\n",
        "CLEAN_DIR = SCRAPE_DIR + 'CLEAN/'\n",
        "\n",
        "CURRENT_DATE = datetime.now(timezone('US/Eastern')).strftime('%m-%d-%Y')"
      ],
      "metadata": {
        "id": "pQLkhi85XBId"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatter for Consistency\n",
        "\n",
        "---\n",
        "\n",
        "We aren't sure if there can be keys other than the ones listed below. \n",
        "\n",
        "For previously unseen keys, we use str.upper() to give them a default value because we want to be able to automate the web scraper, so we want to handle errors without stopping.\n",
        "\n",
        "Any previously unseen keys should be added to the dictionary along with a value to ensure consistency.\n",
        "\n",
        "---\n",
        "\n",
        "## **Ensure all tuples end with a comma**\n",
        "\n",
        "If we have a tuple of a single element, it should look like:  \n",
        "(MY_ELEMENT,)\n",
        "\n",
        "If we do (MY_ELEMENT) this will get parsed character by character, since (MY_ELEMENT) is equivalent to the string MY_ELEMENT."
      ],
      "metadata": {
        "id": "4_iQCJCaWl4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INCONSISTENT_COLUMNS = ['Race', 'Sex', 'Eye Color', 'Hair Color']\n",
        "UNKNOWN_VAL = 'N/A'\n",
        "\n",
        "# We use many-to-one mappings (Dict[Tuple, str]) for convenience - easier to add mappings\n",
        "# We convert them to one-to-one dictionaries later\n",
        "RACE_MAPPINGS = {\n",
        "    ('B', 'Black', 'BLACK',): 'BLACK',\n",
        "    ('W', 'White', 'WHITE',): 'WHITE',\n",
        "    ('H', 'Hispanic', 'HISPANIC',): 'HISPANIC',\n",
        "    ('A', 'INDIAN',): 'ASIAN',\n",
        "    ('Other',): 'OTHER',\n",
        "    ('U', 'UNKNOWN', 'UNDECIDED', 'N/A',): UNKNOWN_VAL,\n",
        "}\n",
        "\n",
        "GENDER_MAPPINGS = {\n",
        "    ('F', 'Female', 'FEMALE',): 'FEMALE',\n",
        "    ('M', 'Male', 'MALE',): 'MALE',\n",
        "    ('',): UNKNOWN_VAL,\n",
        "}\n",
        "\n",
        "EYE_COLOR_MAPPINGS = {\n",
        "    ('GRN', 'Green', 'GREEN',): 'GREEN',\n",
        "    ('HAZ', 'Hazel', 'HAZEL',): 'HAZEL',\n",
        "    ('BLU', 'Blue', 'BLUE',): 'BLUE',\n",
        "    ('BRO', 'Brown', 'BROWN',): 'BROWN',\n",
        "    ('DARK BROWN',): 'DARK BROWN',\n",
        "    ('GRY', 'Gray', 'GRAY',): 'GREY',\n",
        "    ('BLK', 'Black', 'BLACK',): 'BLACK',\n",
        "    ('MAROON',): 'MAROON',\n",
        "    ('UNKN', 'Unknown', 'UNKNOWN',): UNKNOWN_VAL,\n",
        "}\n",
        "\n",
        "HAIR_COLOR_MAPPINGS = {\n",
        "    ('BLK', 'Black', 'BLACK',): 'BLACK',\n",
        "    ('BRO', 'Brown', 'BROWN',): 'BROWN',\n",
        "    ('Blue', 'BLUE',): 'BLUE',\n",
        "    ('GRY', 'Gray', 'GRAY', 'GREY',): 'GREY',\n",
        "    ('WHI', 'White', 'WHITE',): 'WHITE',\n",
        "    ('Red', 'RED',): 'RED',\n",
        "    ('BAL', 'Bald', 'BALD',): 'BALD',\n",
        "    ('Auburn', 'AUBURN',): 'AUBURN',\n",
        "    ('SDY', 'Sandy', 'SANDY',): 'SANDY',\n",
        "    ('BLN', 'Blond', 'BLOND', 'Blonde', 'BLONDE',): 'BLONDE',\n",
        "    ('GREEN',): 'GREEN',\n",
        "    ('Pink', 'PINK',): 'PINK',\n",
        "    ('PURPLE',): 'PURPLE',\n",
        "    ('MULTICOLORED',): 'MULTICOLORED',\n",
        "    ('XXX', 'Unknown', 'NONE',): UNKNOWN_VAL,\n",
        "}"
      ],
      "metadata": {
        "id": "xKGGqV4ckoYo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KoCfjWFYWgGS"
      },
      "outputs": [],
      "source": [
        "class Formatter():\n",
        "    class FormatterDict(dict):\n",
        "        \"\"\"Custom class to handle missing keys by subclassing dict. Currently returns str.upper() for missing keys.\"\"\"\n",
        "\n",
        "        def __missing__(self, key: str) -> str:\n",
        "            print(\"WARNING: Missing key:\", key)\n",
        "            return str.upper(key)\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.race_mappings = self._convert_mapping_to_dict(RACE_MAPPINGS)\n",
        "        self.gender_mappings = self._convert_mapping_to_dict(GENDER_MAPPINGS)\n",
        "        self.eye_color_mappings = self._convert_mapping_to_dict(EYE_COLOR_MAPPINGS)\n",
        "        self.hair_color_mappings = self._convert_mapping_to_dict(HAIR_COLOR_MAPPINGS)\n",
        "\n",
        "    def get_mappings(self, name: str) -> Dict:\n",
        "        if name == 'Race':\n",
        "            return self.race_mappings\n",
        "        elif name == 'Sex':\n",
        "            return self.gender_mappings\n",
        "        elif name == 'Eye Color':\n",
        "            return self.eye_color_mappings\n",
        "        elif name == 'Hair Color':\n",
        "            return self.hair_color_mappings\n",
        "        else:\n",
        "            raise Exception(\"ERROR: Unrecognized name\", name)\n",
        "\n",
        "    def format_column(self, column: pd.Series) -> pd.Series:\n",
        "        # Ignore columns that are completely null\n",
        "        if column.isnull().all() == True:\n",
        "            return column\n",
        "\n",
        "        # Remove any trailing whitespace\n",
        "        column = column.str.rstrip()\n",
        "\n",
        "        mappings = self.get_mappings(column.name)\n",
        "        return column.map(mappings, na_action='ignore')\n",
        "\n",
        "    def format_df(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        # Remove any columns not found in the dataframe\n",
        "        columns_to_fix = [col for col in INCONSISTENT_COLUMNS if col in df.columns]\n",
        "\n",
        "        # Fix inconsistent data formatting\n",
        "        df[columns_to_fix] = df[columns_to_fix].apply(self.format_column)\n",
        "        return df\n",
        "\n",
        "    def _convert_mapping_to_dict(self, many_to_one: Dict) -> Dict:\n",
        "        \"\"\"Convert a many-to-one dictionary to a one-to-one dictionary.\n",
        "        For example:\n",
        "        {('key_1', 'key_2'): 'val'} -> {'key_1': 'val', 'key_2': 'val'}\n",
        "        \"\"\"\n",
        "        one_to_one = self.FormatterDict()\n",
        "        for key_tuple, val in many_to_one.items():\n",
        "            # Safety check for user error\n",
        "            if type(key_tuple) != tuple:\n",
        "                raise Exception(\"ERROR: Key tuple entered incorrectly!\", key_tuple)\n",
        "\n",
        "            for key in key_tuple:\n",
        "                one_to_one[key] = val\n",
        "        return one_to_one"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data\n",
        "\n",
        "---\n",
        "\n",
        "This will automatically clean the data for the current day. If needed, this can be expanded to clean data from previous days."
      ],
      "metadata": {
        "id": "rKVrclAkXfFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATES_TO_CLEAN = os.listdir(DATA_DIR)\n",
        "DATES_TO_CLEAN = [CURRENT_DATE]\n",
        "formatter = Formatter()\n",
        "\n",
        "for date_to_clean in DATES_TO_CLEAN:\n",
        "    print(\"Cleaning date:\", date_to_clean)\n",
        "    dir_to_clean = f'{DATA_DIR}{date_to_clean}'\n",
        "    for sub_dir, dirs, files in os.walk(dir_to_clean):\n",
        "        for filename in files:\n",
        "            cur_file = f'{sub_dir}/{filename}'\n",
        "\n",
        "            df = pd.read_csv(cur_file)\n",
        "\n",
        "            # Ignore the index column present in some files\n",
        "            # https://stackoverflow.com/a/43983654\n",
        "            df.drop(df.columns[df.columns.str.contains('^Unnamed')], axis=1, inplace=True)\n",
        "            df = formatter.format_df(df)\n",
        "\n",
        "            # Create directory if needed\n",
        "            new_dir = f'{CLEAN_DIR}{date_to_clean}'\n",
        "            os.makedirs(new_dir, exist_ok=True)\n",
        "\n",
        "            df.to_csv(f'{new_dir}/{filename}', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XQGhTkoXgaY",
        "outputId": "705e3198-fbd3-4b4a-a8ff-7869cc11b283"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning date: 03-04-2022\n",
            "Cleaning date: 03-05-2022\n",
            "Cleaning date: 03-06-2022\n",
            "Cleaning date: 03-08-2022\n",
            "Cleaning date: 03-09-2022\n",
            "Cleaning date: 03-10-2022\n",
            "Cleaning date: 03-11-2022\n",
            "Cleaning date: 03-12-2022\n",
            "Cleaning date: 03-13-2022\n",
            "Cleaning date: 03-14-2022\n",
            "Cleaning date: 03-15-2022\n",
            "Cleaning date: 03-16-2022\n",
            "Cleaning date: 03-17-2022\n",
            "Cleaning date: 03-18-2022\n",
            "Cleaning date: 03-19-2022\n",
            "Cleaning date: 03-20-2022\n"
          ]
        }
      ]
    }
  ]
}